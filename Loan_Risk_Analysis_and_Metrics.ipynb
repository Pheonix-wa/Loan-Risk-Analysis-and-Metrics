{
  "cells": [
    {
      "metadata": {
        "_uuid": "3fd8e11c1ff348d6b1579a18fe737cec265e04aa",
        "_cell_guid": "60cdff95-e165-4ef7-82bb-be2d3d799248",
        "id": "gqtBVq2yCNYJ"
      },
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\"> Comprehensive Loan Risk Analysis and Metrics </h1> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "a7b75f3526a75485e089933ae775aec5555fe2ce",
        "_cell_guid": "07ed872d-6dbb-4c7e-9244-7f565e0c7d38",
        "id": "jg_MujqtCNYO"
      },
      "cell_type": "markdown",
      "source": [
        "# Introduction:\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "d65b7b14701cf9c42ec8cbb1ecfdfe6ab3358ae7",
        "_cell_guid": "428e7e85-93ed-45b1-aa24-cba4a771c2f3",
        "trusted": true,
        "id": "1qGgMTMVCNYP"
      },
      "cell_type": "code",
      "source": [
        "# Import our libraries we are going to use for our data analysis.\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotly visualizations\n",
        "from plotly import tools\n",
        "import plotly.plotly as py\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "init_notebook_mode(connected=True)\n",
        "# plotly.tools.set_credentials_file(username='AlexanderBach', api_key='o4fx6i1MtEIJQxfWYvU1')\n",
        "\n",
        "\n",
        "# For oversampling Library (Dealing with Imbalanced Datasets)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# Other Libraries\n",
        "import time\n",
        "\n",
        "\n",
        "% matplotlib inline\n",
        "\n",
        "df = pd.read_csv('../input/loan.csv', low_memory=False)\n",
        "\n",
        "# Copy of the dataframe\n",
        "original_df = df.copy()\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0ee2926e3668a0c3beb7b06ce9f14809c1e37053",
        "_cell_guid": "7e81133a-2dbe-4126-8ad6-e1c84efa915f",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "n9b2gT94CNYQ"
      },
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0ff8dc19af3f2ad57e2c9c8c02a2047fb502bd1e",
        "_cell_guid": "f054ecf3-735e-4ff8-a701-9210507e1cac",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "k-uhxmYPCNYR"
      },
      "cell_type": "code",
      "source": [
        "# Replace the name of some columns\n",
        "df = df.rename(columns={\"loan_amnt\": \"loan_amount\", \"funded_amnt\": \"funded_amount\", \"funded_amnt_inv\": \"investor_funds\",\n",
        "                       \"int_rate\": \"interest_rate\", \"annual_inc\": \"annual_income\"})\n",
        "\n",
        "# Drop irrelevant columns\n",
        "df.drop(['id', 'member_id', 'emp_title', 'url', 'desc', 'zip_code', 'title'], axis=1, inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ab357844a9985a3783a813423e08f5166830203b",
        "_cell_guid": "9390f158-796f-4f69-b145-b1d2a5584745",
        "id": "UTrYMlBFCNYS"
      },
      "cell_type": "markdown",
      "source": [
        "## Similar Distributions:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "dca1e813e0820c7e422c4eadf66e2a71fda28b94",
        "_cell_guid": "fe7b0217-b372-444e-9f6c-d1ed5fe5259c",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "cothbQj_CNYS"
      },
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(16,5))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "loan_amount = df[\"loan_amount\"].values\n",
        "funded_amount = df[\"funded_amount\"].values\n",
        "investor_funds = df[\"investor_funds\"].values\n",
        "\n",
        "\n",
        "sns.distplot(loan_amount, ax=ax[0], color=\"#F7522F\")\n",
        "ax[0].set_title(\"Loan Applied by the Borrower\", fontsize=14)\n",
        "sns.distplot(funded_amount, ax=ax[1], color=\"#2F8FF7\")\n",
        "ax[1].set_title(\"Amount Funded by the Lender\", fontsize=14)\n",
        "sns.distplot(investor_funds, ax=ax[2], color=\"#2EAD46\")\n",
        "ax[2].set_title(\"Total committed by Investors\", fontsize=14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "de70a0eb750a61d68838339b3bf60f9136585c29",
        "_cell_guid": "b0d59461-2e0f-44e7-bb9c-7dc57934b488",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "IsYX3HG3CNYT"
      },
      "cell_type": "code",
      "source": [
        "# Lets' transform the issue dates by year.\n",
        "df['issue_d'].head()\n",
        "dt_series = pd.to_datetime(df['issue_d'])\n",
        "df['year'] = dt_series.dt.year"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wCDgqULrE6AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "04a7f159ba7620fd10780e7ff9c1320f428f83b5",
        "_cell_guid": "61bff410-2904-4f17-93e5-c724a778e019",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "XgADpr0QCNYU"
      },
      "cell_type": "code",
      "source": [
        "# The year of 2015 was the year were the highest amount of loans were issued\n",
        "# This is an indication that the economy is quiet recovering itself.\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot('year', 'loan_amount', data=df, palette='tab10')\n",
        "plt.title('Issuance of Loans', fontsize=16)\n",
        "plt.xlabel('Year', fontsize=14)\n",
        "plt.ylabel('Average loan amount issued', fontsize=14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cc873fd882cba9ee89a01f64ce9b390fdc3b9f25",
        "_cell_guid": "68557789-fb4c-43d9-a5c5-f588085aace7",
        "id": "AtteNvLdCNYV"
      },
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\"> Good Loans vs Bad Loans: </h1>\n",
        "<h2>Types of Loans: </h2>\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "f6cd906337ab70e068887b011bd29dd1e628b0f1",
        "_cell_guid": "85412154-d30d-4f7f-96b2-d41b6d94ab74",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "ERvRYJLiCNYW"
      },
      "cell_type": "code",
      "source": [
        "df[\"loan_status\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6fd3553700f3eb4889e88517d2b8e5b7d904872e",
        "_cell_guid": "61d96d6a-f3f8-4a34-a4c8-3d77c4ebee31",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "_asINvZyCNYW"
      },
      "cell_type": "code",
      "source": [
        "# Determining the loans that are bad from loan_status column\n",
        "\n",
        "bad_loan = [\"Charged Off\", \"Default\", \"Does not meet the credit policy. Status:Charged Off\", \"In Grace Period\",\n",
        "            \"Late (16-30 days)\", \"Late (31-120 days)\"]\n",
        "\n",
        "\n",
        "df['loan_condition'] = np.nan\n",
        "\n",
        "def loan_condition(status):\n",
        "    if status in bad_loan:\n",
        "        return 'Bad Loan'\n",
        "    else:\n",
        "        return 'Good Loan'\n",
        "\n",
        "\n",
        "df['loan_condition'] = df['loan_status'].apply(loan_condition)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "596bd11ee859fec86ca3a4469b6f98a7f13f4035",
        "_cell_guid": "ac878d77-5702-4daf-adfe-d61657043e90",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "FWNjV3STCNYX"
      },
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots(1,2, figsize=(16,8))\n",
        "\n",
        "colors = [\"#3791D7\", \"#D72626\"]\n",
        "labels =\"Good Loans\", \"Bad Loans\"\n",
        "\n",
        "plt.suptitle('Information on Loan Conditions', fontsize=20)\n",
        "\n",
        "df[\"loan_condition\"].value_counts().plot.pie(explode=[0,0.25], autopct='%1.2f%%', ax=ax[0], shadow=True, colors=colors,\n",
        "                                             labels=labels, fontsize=12, startangle=70)\n",
        "\n",
        "\n",
        "# ax[0].set_title('State of Loan', fontsize=16)\n",
        "ax[0].set_ylabel('% of Condition of Loans', fontsize=14)\n",
        "\n",
        "# sns.countplot('loan_condition', data=df, ax=ax[1], palette=colors)\n",
        "# ax[1].set_title('Condition of Loans', fontsize=20)\n",
        "# ax[1].set_xticklabels(['Good', 'Bad'], rotation='horizontal')\n",
        "palette = [\"#3791D7\", \"#E01E1B\"]\n",
        "\n",
        "sns.barplot(x=\"year\", y=\"loan_amount\", hue=\"loan_condition\", data=df, palette=palette, estimator=lambda x: len(x) / len(df) * 100)\n",
        "ax[1].set(ylabel=\"(%)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cef68413efdb6b4f48b0c640bd0c5e877800ede1",
        "_cell_guid": "6871315f-0d27-4b08-8502-247fb711ec50",
        "id": "wqvP4U_hCNYY"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> Loans Issued by Region</h2>\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "3af220b72bb3bfd067086f3c2049b6e04da0808c",
        "_cell_guid": "f82148c1-5a13-4af0-b7b3-c6fb767864ca",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "rUZQaxs4CNYY"
      },
      "cell_type": "code",
      "source": [
        "df['addr_state'].unique()\n",
        "\n",
        "# Make a list with each of the regions by state.\n",
        "\n",
        "west = ['CA', 'OR', 'UT','WA', 'CO', 'NV', 'AK', 'MT', 'HI', 'WY', 'ID']\n",
        "south_west = ['AZ', 'TX', 'NM', 'OK']\n",
        "south_east = ['GA', 'NC', 'VA', 'FL', 'KY', 'SC', 'LA', 'AL', 'WV', 'DC', 'AR', 'DE', 'MS', 'TN' ]\n",
        "mid_west = ['IL', 'MO', 'MN', 'OH', 'WI', 'KS', 'MI', 'SD', 'IA', 'NE', 'IN', 'ND']\n",
        "north_east = ['CT', 'NY', 'PA', 'NJ', 'RI','MA', 'MD', 'VT', 'NH', 'ME']\n",
        "\n",
        "\n",
        "\n",
        "df['region'] = np.nan\n",
        "\n",
        "def finding_regions(state):\n",
        "    if state in west:\n",
        "        return 'West'\n",
        "    elif state in south_west:\n",
        "        return 'SouthWest'\n",
        "    elif state in south_east:\n",
        "        return 'SouthEast'\n",
        "    elif state in mid_west:\n",
        "        return 'MidWest'\n",
        "    elif state in north_east:\n",
        "        return 'NorthEast'\n",
        "\n",
        "\n",
        "\n",
        "df['region'] = df['addr_state'].apply(finding_regions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "03f1590c7a754ccba10fd3a7051a587f4a4b98da",
        "_cell_guid": "74afbde0-508f-4bfb-92de-373c3f6dd0e2",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "aUDmfiRKCNYZ"
      },
      "cell_type": "code",
      "source": [
        "# This code will take the current date and transform it into a year-month format\n",
        "df['complete_date'] = pd.to_datetime(df['issue_d'])\n",
        "\n",
        "group_dates = df.groupby(['complete_date', 'region'], as_index=False).sum()\n",
        "\n",
        "group_dates['issue_d'] = [month.to_period('M') for\n",
        "                          month in group_dates['complete_date']]\n",
        "\n",
        "group_dates = group_dates.groupby(['issue_d', 'region'], as_index=False).sum()\n",
        "group_dates = group_dates.groupby(['issue_d', 'region'], as_index=False).sum()\n",
        "group_dates['loan_amount'] = group_dates['loan_amount']/1000\n",
        "\n",
        "\n",
        "df_dates = pd.DataFrame(data=group_dates[['issue_d','region','loan_amount']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a1c7340953b00c99b113e915a39bfc6457fc4981",
        "_cell_guid": "9de5aa56-be65-49bc-8c02-a12eca0f8aa0",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "EJV3jfMMCNYZ"
      },
      "cell_type": "code",
      "source": [
        "plt.style.use('dark_background')\n",
        "cmap = plt.cm.Set3\n",
        "\n",
        "by_issued_amount = df_dates.groupby(['issue_d', 'region']).loan_amount.sum()\n",
        "by_issued_amount.unstack().plot(stacked=False, colormap=cmap, grid=False, legend=True, figsize=(15,6))\n",
        "\n",
        "plt.title('Loans issued by Region', fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b26ef6d24ea7d2dc41fe2a2626694399e61b6141",
        "_cell_guid": "5fe5597b-abd4-4366-88b5-7c735692b0c2",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "ivPLBwYMCNYZ"
      },
      "cell_type": "code",
      "source": [
        "employment_length = ['10+ years', '< 1 year', '1 year', '3 years', '8 years', '9 years',\n",
        "                    '4 years', '5 years', '6 years', '2 years', '7 years', 'n/a']\n",
        "\n",
        "# Create a new column and convert emp_length to integers.\n",
        "\n",
        "lst = [df]\n",
        "df['emp_length_int'] = np.nan\n",
        "\n",
        "for col in lst:\n",
        "    col.loc[col['emp_length'] == '10+ years', \"emp_length_int\"] = 10\n",
        "    col.loc[col['emp_length'] == '9 years', \"emp_length_int\"] = 9\n",
        "    col.loc[col['emp_length'] == '8 years', \"emp_length_int\"] = 8\n",
        "    col.loc[col['emp_length'] == '7 years', \"emp_length_int\"] = 7\n",
        "    col.loc[col['emp_length'] == '6 years', \"emp_length_int\"] = 6\n",
        "    col.loc[col['emp_length'] == '5 years', \"emp_length_int\"] = 5\n",
        "    col.loc[col['emp_length'] == '4 years', \"emp_length_int\"] = 4\n",
        "    col.loc[col['emp_length'] == '3 years', \"emp_length_int\"] = 3\n",
        "    col.loc[col['emp_length'] == '2 years', \"emp_length_int\"] = 2\n",
        "    col.loc[col['emp_length'] == '1 year', \"emp_length_int\"] = 1\n",
        "    col.loc[col['emp_length'] == '< 1 year', \"emp_length_int\"] = 0.5\n",
        "    col.loc[col['emp_length'] == 'n/a', \"emp_length_int\"] = 0\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fc10ef7575055551e8bce935b642c0fcceb93527",
        "_cell_guid": "8c453a61-ce53-459b-bf38-d02a56d24b81",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "Zcr4xtlXCNYZ"
      },
      "cell_type": "code",
      "source": [
        "# Loan issued by Region and by Credit Score grade\n",
        "# Change the colormap for tomorrow!\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
        "cmap = plt.cm.inferno\n",
        "\n",
        "by_interest_rate = df.groupby(['year', 'region']).interest_rate.mean()\n",
        "by_interest_rate.unstack().plot(kind='area', stacked=True, colormap=cmap, grid=False, legend=False, ax=ax1, figsize=(16,12))\n",
        "ax1.set_title('Average Interest Rate by Region', fontsize=14)\n",
        "\n",
        "\n",
        "by_employment_length = df.groupby(['year', 'region']).emp_length_int.mean()\n",
        "by_employment_length.unstack().plot(kind='area', stacked=True, colormap=cmap, grid=False, legend=False, ax=ax2, figsize=(16,12))\n",
        "ax2.set_title('Average Employment Length by Region', fontsize=14)\n",
        "# plt.xlabel('Year of Issuance', fontsize=14)\n",
        "\n",
        "by_dti = df.groupby(['year', 'region']).dti.mean()\n",
        "by_dti.unstack().plot(kind='area', stacked=True, colormap=cmap, grid=False, legend=False, ax=ax3, figsize=(16,12))\n",
        "ax3.set_title('Average Debt-to-Income by Region', fontsize=14)\n",
        "\n",
        "by_income = df.groupby(['year', 'region']).annual_income.mean()\n",
        "by_income.unstack().plot(kind='area', stacked=True, colormap=cmap, grid=False, ax=ax4, figsize=(16,12))\n",
        "ax4.set_title('Average Annual Income by Region', fontsize=14)\n",
        "ax4.legend(bbox_to_anchor=(-1.0, -0.5, 1.8, 0.1), loc=10,prop={'size':12},\n",
        "           ncol=5, mode=\"expand\", borderaxespad=0.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "234064b3f172cd733f7f416149b663b37ab4268b",
        "_cell_guid": "ec3c1e24-70e6-45bb-97ea-4c42ff69f84d",
        "id": "fIbKsINZCNYa"
      },
      "cell_type": "markdown",
      "source": [
        "## A Deeper Look into Bad Loans:\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "b72bf3be29058e6f859939ea2f81a0f226a931e4",
        "_cell_guid": "4ec04af3-a602-4547-982d-f42dd15b2914",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "jBjyAwtdCNYa"
      },
      "cell_type": "code",
      "source": [
        "# We have 67429 loans categorized as bad loans\n",
        "badloans_df = df.loc[df[\"loan_condition\"] == \"Bad Loan\"]\n",
        "\n",
        "# loan_status cross\n",
        "loan_status_cross = pd.crosstab(badloans_df['region'], badloans_df['loan_status']).apply(lambda x: x/x.sum() * 100)\n",
        "number_of_loanstatus = pd.crosstab(badloans_df['region'], badloans_df['loan_status'])\n",
        "\n",
        "\n",
        "# Round our values\n",
        "loan_status_cross['Charged Off'] = loan_status_cross['Charged Off'].apply(lambda x: round(x, 2))\n",
        "loan_status_cross['Default'] = loan_status_cross['Default'].apply(lambda x: round(x, 2))\n",
        "loan_status_cross['Does not meet the credit policy. Status:Charged Off'] = loan_status_cross['Does not meet the credit policy. Status:Charged Off'].apply(lambda x: round(x, 2))\n",
        "loan_status_cross['In Grace Period'] = loan_status_cross['In Grace Period'].apply(lambda x: round(x, 2))\n",
        "loan_status_cross['Late (16-30 days)'] = loan_status_cross['Late (16-30 days)'].apply(lambda x: round(x, 2))\n",
        "loan_status_cross['Late (31-120 days)'] = loan_status_cross['Late (31-120 days)'].apply(lambda x: round(x, 2))\n",
        "\n",
        "\n",
        "number_of_loanstatus['Total'] = number_of_loanstatus.sum(axis=1)\n",
        "# number_of_badloans\n",
        "number_of_loanstatus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f18e32fe594a649502c501c296dc0ea75bd709d3",
        "_cell_guid": "2924ac56-0368-45e1-8474-3d3ffb78651c",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "g4d9vC43CNYb"
      },
      "cell_type": "code",
      "source": [
        "charged_off = loan_status_cross['Charged Off'].values.tolist()\n",
        "default = loan_status_cross['Default'].values.tolist()\n",
        "not_meet_credit = loan_status_cross['Does not meet the credit policy. Status:Charged Off'].values.tolist()\n",
        "grace_period = loan_status_cross['In Grace Period'].values.tolist()\n",
        "short_pay = loan_status_cross['Late (16-30 days)'] .values.tolist()\n",
        "long_pay = loan_status_cross['Late (31-120 days)'].values.tolist()\n",
        "\n",
        "\n",
        "\n",
        "charged = go.Bar(\n",
        "    x=['MidWest', 'NorthEast', 'SouthEast', 'SouthWest', 'West'],\n",
        "    y= charged_off,\n",
        "    name='Charged Off',\n",
        "    marker=dict(\n",
        "        color='rgb(192, 148, 246)'\n",
        "    ),\n",
        "    text = '%'\n",
        ")\n",
        "\n",
        "defaults = go.Bar(\n",
        "    x=['MidWest', 'NorthEast', 'SouthEast', 'SouthWest', 'West'],\n",
        "    y=default,\n",
        "    name='Defaults',\n",
        "    marker=dict(\n",
        "        color='rgb(176, 26, 26)'\n",
        "    ),\n",
        "    text = '%'\n",
        ")\n",
        "\n",
        "credit_policy = go.Bar(\n",
        "    x=['MidWest', 'NorthEast', 'SouthEast', 'SouthWest', 'West'],\n",
        "    y= not_meet_credit,\n",
        "    name='Does not meet Credit Policy',\n",
        "    marker = dict(\n",
        "        color='rgb(229, 121, 36)'\n",
        "    ),\n",
        "    text = '%'\n",
        ")\n",
        "\n",
        "grace = go.Bar(\n",
        "    x=['MidWest', 'NorthEast', 'SouthEast', 'SouthWest', 'West'],\n",
        "    y= grace_period,\n",
        "    name='Grace Period',\n",
        "    marker = dict(\n",
        "        color='rgb(147, 147, 147)'\n",
        "    ),\n",
        "    text = '%'\n",
        ")\n",
        "\n",
        "short_pays = go.Bar(\n",
        "    x=['MidWest', 'NorthEast', 'SouthEast', 'SouthWest', 'West'],\n",
        "    y= short_pay,\n",
        "    name='Late Payment (16-30 days)',\n",
        "    marker = dict(\n",
        "        color='rgb(246, 157, 135)'\n",
        "    ),\n",
        "    text = '%'\n",
        ")\n",
        "\n",
        "long_pays = go.Bar(\n",
        "    x=['MidWest', 'NorthEast', 'SouthEast', 'SouthWest', 'West'],\n",
        "    y= long_pay,\n",
        "    name='Late Payment (31-120 days)',\n",
        "    marker = dict(\n",
        "        color = 'rgb(238, 76, 73)'\n",
        "        ),\n",
        "    text = '%'\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = [charged, defaults, credit_policy, grace, short_pays, long_pays]\n",
        "layout = go.Layout(\n",
        "    barmode='stack',\n",
        "    title = '% of Bad Loan Status by Region',\n",
        "    xaxis=dict(title='US Regions')\n",
        ")\n",
        "\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "iplot(fig, filename='stacked-bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "66fe044e83e0695eda2817ee8e02e8ed6e03fccb",
        "_cell_guid": "5da6bde7-19fb-475c-a594-125288851fb5",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "S1zlW841CNYb"
      },
      "cell_type": "code",
      "source": [
        "# Average interest rates clients pay\n",
        "df['interest_rate'].mean()\n",
        "# Average annual income of clients\n",
        "df['annual_income'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "138a17bf8f796d021221755065c174401cdff6c2",
        "_cell_guid": "22cce5bc-2b49-4c3a-9966-3d9b0e07c250",
        "id": "0BIKBzW0CNYb"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h2 > Understanding the Operative Side of Business </h2>\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "2d6663f515fcb697b6b0bc4bf138734e3d6beae9",
        "_cell_guid": "23bcd908-a7fe-455e-a658-59b6fd9b7d64",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "Md6gKfzICNYc"
      },
      "cell_type": "code",
      "source": [
        "# Plotting by states\n",
        "\n",
        "# Grouping by our metrics\n",
        "# First Plotly Graph (We evaluate the operative side of the business)\n",
        "by_loan_amount = df.groupby(['region','addr_state'], as_index=False).loan_amount.sum()\n",
        "by_interest_rate = df.groupby(['region', 'addr_state'], as_index=False).interest_rate.mean()\n",
        "by_income = df.groupby(['region', 'addr_state'], as_index=False).annual_income.mean()\n",
        "\n",
        "\n",
        "\n",
        "# Take the values to a list for visualization purposes.\n",
        "states = by_loan_amount['addr_state'].values.tolist()\n",
        "average_loan_amounts = by_loan_amount['loan_amount'].values.tolist()\n",
        "average_interest_rates = by_interest_rate['interest_rate'].values.tolist()\n",
        "average_annual_income = by_income['annual_income'].values.tolist()\n",
        "\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Figure Number 1 (Perspective for the Business Operations)\n",
        "metrics_data = OrderedDict([('state_codes', states),\n",
        "                            ('issued_loans', average_loan_amounts),\n",
        "                            ('interest_rate', average_interest_rates),\n",
        "                            ('annual_income', average_annual_income)])\n",
        "\n",
        "\n",
        "metrics_df = pd.DataFrame.from_dict(metrics_data)\n",
        "metrics_df = metrics_df.round(decimals=2)\n",
        "metrics_df.head()\n",
        "\n",
        "\n",
        "\n",
        "# Think of a way to add default rate\n",
        "# Consider adding a few more metrics for the future"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d034ebaaa95dd36353bb96665bcca7117a56a7c5",
        "_cell_guid": "9658d3df-f822-4d89-ae55-cb1e2559507b",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "tR5vWvTDCNYd"
      },
      "cell_type": "code",
      "source": [
        "# Now it comes the part where we plot out plotly United States map\n",
        "import plotly.plotly as py\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "\n",
        "for col in metrics_df.columns:\n",
        "    metrics_df[col] = metrics_df[col].astype(str)\n",
        "\n",
        "scl = [[0.0, 'rgb(210, 241, 198)'],[0.2, 'rgb(188, 236, 169)'],[0.4, 'rgb(171, 235, 145)'],\\\n",
        "            [0.6, 'rgb(140, 227, 105)'],[0.8, 'rgb(105, 201, 67)'],[1.0, 'rgb(59, 159, 19)']]\n",
        "\n",
        "metrics_df['text'] = metrics_df['state_codes'] + '<br>' +\\\n",
        "'Average loan interest rate: ' + metrics_df['interest_rate'] + '<br>'+\\\n",
        "'Average annual income: ' + metrics_df['annual_income']\n",
        "\n",
        "\n",
        "data = [ dict(\n",
        "        type='choropleth',\n",
        "        colorscale = scl,\n",
        "        autocolorscale = False,\n",
        "        locations = metrics_df['state_codes'],\n",
        "        z = metrics_df['issued_loans'],\n",
        "        locationmode = 'USA-states',\n",
        "        text = metrics_df['text'],\n",
        "        marker = dict(\n",
        "            line = dict (\n",
        "                color = 'rgb(255,255,255)',\n",
        "                width = 2\n",
        "            ) ),\n",
        "        colorbar = dict(\n",
        "            title = \"$s USD\")\n",
        "        ) ]\n",
        "\n",
        "\n",
        "layout = dict(\n",
        "    title = 'Lending Clubs Issued Loans <br> (A Perspective for the Business Operations)',\n",
        "    geo = dict(\n",
        "        scope = 'usa',\n",
        "        projection=dict(type='albers usa'),\n",
        "        showlakes = True,\n",
        "        lakecolor = 'rgb(255, 255, 255)')\n",
        ")\n",
        "\n",
        "fig = dict(data=data, layout=layout)\n",
        "iplot(fig, filename='d3-cloropleth-map')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "afa20ec1ac2f9c7170e0bf5def350833db1526ff",
        "_cell_guid": "70d317a6-1c8f-497e-95b0-484931a6505e",
        "id": "9_Ja4vRuCNYe"
      },
      "cell_type": "markdown",
      "source": [
        "## Analysis by Income Category:\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "91adcc85d6847933a074c9687c16755d1cb2b4d5",
        "_cell_guid": "9703d5e9-d59b-4ed3-8a7c-ffb2eb118482",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "u_EisBzeCNYe"
      },
      "cell_type": "code",
      "source": [
        "# Let's create categories for annual_income since most of the bad loans are located below 100k\n",
        "\n",
        "df['income_category'] = np.nan\n",
        "lst = [df]\n",
        "\n",
        "for col in lst:\n",
        "    col.loc[col['annual_income'] <= 100000, 'income_category'] = 'Low'\n",
        "    col.loc[(col['annual_income'] > 100000) & (col['annual_income'] <= 200000), 'income_category'] = 'Medium'\n",
        "    col.loc[col['annual_income'] > 200000, 'income_category'] = 'High'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "306437009da2006a4253e97bdd09b8b6f3f5b2d1",
        "_cell_guid": "697206b1-4a51-4b71-816c-f683e1e1e1b3",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "MnEpJ0oDCNYf"
      },
      "cell_type": "code",
      "source": [
        "# Let's transform the column loan_condition into integrers.\n",
        "\n",
        "lst = [df]\n",
        "df['loan_condition_int'] = np.nan\n",
        "\n",
        "for col in lst:\n",
        "    col.loc[df['loan_condition'] == 'Good Loan', 'loan_condition_int'] = 0 # Negative (Bad Loan)\n",
        "    col.loc[df['loan_condition'] == 'Bad Loan', 'loan_condition_int'] = 1 # Positive (Good Loan)\n",
        "\n",
        "# Convert from float to int the column (This is our label)\n",
        "df['loan_condition_int'] = df['loan_condition_int'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "69859cabf2fb48c3f6efb3e1256035bf3f57f270",
        "_cell_guid": "ba55fd70-e3aa-4e97-869e-d4af2928f0b1",
        "trusted": true,
        "id": "CDQ03OPDCNYf"
      },
      "cell_type": "code",
      "source": [
        "fig, ((ax1, ax2), (ax3, ax4))= plt.subplots(nrows=2, ncols=2, figsize=(14,6))\n",
        "\n",
        "# Change the Palette types tomorrow!\n",
        "\n",
        "sns.violinplot(x=\"income_category\", y=\"loan_amount\", data=df, palette=\"Set2\", ax=ax1 )\n",
        "sns.violinplot(x=\"income_category\", y=\"loan_condition_int\", data=df, palette=\"Set2\", ax=ax2)\n",
        "sns.boxplot(x=\"income_category\", y=\"emp_length_int\", data=df, palette=\"Set2\", ax=ax3)\n",
        "sns.boxplot(x=\"income_category\", y=\"interest_rate\", data=df, palette=\"Set2\", ax=ax4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9f4ca83a49dd49ba2cdef23a6f98ef02ca413c12",
        "_cell_guid": "a5762c82-4b5c-457e-9295-f7732c21d38c",
        "id": "WUwh7ueoCNYf"
      },
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\"> Assesing Risks </h1>\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "222fe26e9f614a715da22bcdd1f10746d76d35a2",
        "_cell_guid": "43d99fa7-4658-4463-bb49-74ed4d0e1063",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "Zzw_Jga8CNYg"
      },
      "cell_type": "code",
      "source": [
        "by_condition = df.groupby('addr_state')['loan_condition'].value_counts()/ df.groupby('addr_state')['loan_condition'].count()\n",
        "by_emp_length = df.groupby(['region', 'addr_state'], as_index=False).emp_length_int.mean().sort_values(by=\"addr_state\")\n",
        "\n",
        "loan_condition_bystate = pd.crosstab(df['addr_state'], df['loan_condition'] )\n",
        "\n",
        "cross_condition = pd.crosstab(df[\"addr_state\"], df[\"loan_condition\"])\n",
        "# Percentage of condition of loan\n",
        "percentage_loan_contributor = pd.crosstab(df['addr_state'], df['loan_condition']).apply(lambda x: x/x.sum() * 100)\n",
        "condition_ratio = cross_condition[\"Bad Loan\"]/cross_condition[\"Good Loan\"]\n",
        "by_dti = df.groupby(['region', 'addr_state'], as_index=False).dti.mean()\n",
        "state_codes = sorted(states)\n",
        "\n",
        "\n",
        "# Take to a list\n",
        "default_ratio = condition_ratio.values.tolist()\n",
        "average_dti = by_dti['dti'].values.tolist()\n",
        "average_emp_length = by_emp_length[\"emp_length_int\"].values.tolist()\n",
        "number_of_badloans = loan_condition_bystate['Bad Loan'].values.tolist()\n",
        "percentage_ofall_badloans = percentage_loan_contributor['Bad Loan'].values.tolist()\n",
        "\n",
        "\n",
        "# Figure Number 2\n",
        "risk_data = OrderedDict([('state_codes', state_codes),\n",
        "                         ('default_ratio', default_ratio),\n",
        "                         ('badloans_amount', number_of_badloans),\n",
        "                         ('percentage_of_badloans', percentage_ofall_badloans),\n",
        "                         ('average_dti', average_dti),\n",
        "                         ('average_emp_length', average_emp_length)])\n",
        "\n",
        "\n",
        "# Figure 2 Dataframe\n",
        "risk_df = pd.DataFrame.from_dict(risk_data)\n",
        "risk_df = risk_df.round(decimals=3)\n",
        "risk_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2e1e336a86a51b03a20f29776c994b03e4cf5a63",
        "_cell_guid": "39a3e3fb-c123-4258-8d56-99f48954c4df",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "KPYGgTbbCNYg"
      },
      "cell_type": "code",
      "source": [
        "# Now it comes the part where we plot out plotly United States map\n",
        "import plotly.plotly as py\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "\n",
        "for col in risk_df.columns:\n",
        "    risk_df[col] = risk_df[col].astype(str)\n",
        "\n",
        "scl = [[0.0, 'rgb(202, 202, 202)'],[0.2, 'rgb(253, 205, 200)'],[0.4, 'rgb(252, 169, 161)'],\\\n",
        "            [0.6, 'rgb(247, 121, 108  )'],[0.8, 'rgb(232, 70, 54)'],[1.0, 'rgb(212, 31, 13)']]\n",
        "\n",
        "risk_df['text'] = risk_df['state_codes'] + '<br>' +\\\n",
        "'Number of Bad Loans: ' + risk_df['badloans_amount'] + '<br>' + \\\n",
        "'Percentage of all Bad Loans: ' + risk_df['percentage_of_badloans'] + '%' +  '<br>' + \\\n",
        "'Average Debt-to-Income Ratio: ' + risk_df['average_dti'] + '<br>'+\\\n",
        "'Average Length of Employment: ' + risk_df['average_emp_length']\n",
        "\n",
        "\n",
        "data = [ dict(\n",
        "        type='choropleth',\n",
        "        colorscale = scl,\n",
        "        autocolorscale = False,\n",
        "        locations = risk_df['state_codes'],\n",
        "        z = risk_df['default_ratio'],\n",
        "        locationmode = 'USA-states',\n",
        "        text = risk_df['text'],\n",
        "        marker = dict(\n",
        "            line = dict (\n",
        "                color = 'rgb(255,255,255)',\n",
        "                width = 2\n",
        "            ) ),\n",
        "        colorbar = dict(\n",
        "            title = \"%\")\n",
        "        ) ]\n",
        "\n",
        "\n",
        "layout = dict(\n",
        "    title = 'Lending Clubs Default Rates <br> (Analyzing Risks)',\n",
        "    geo = dict(\n",
        "        scope = 'usa',\n",
        "        projection=dict(type='albers usa'),\n",
        "        showlakes = True,\n",
        "        lakecolor = 'rgb(255, 255, 255)')\n",
        ")\n",
        "\n",
        "fig = dict(data=data, layout=layout)\n",
        "iplot(fig, filename='d3-cloropleth-map')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "be1fa255c95aabede8da476fdfedd40da5b3b4a6",
        "_cell_guid": "cbe5e3e3-289c-45f8-9cb9-e5792363fd53",
        "id": "Awbm3hSJCNYg"
      },
      "cell_type": "markdown",
      "source": [
        "## The Importance of Credit Scores:\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "0a0df1473572f180ac8a4c94b9fca66ed80634f6",
        "_cell_guid": "72c471f0-91a8-4e19-bd7c-16704f30501c",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "YKGpWyzTCNYh"
      },
      "cell_type": "code",
      "source": [
        "# Let's visualize how many loans were issued by creditscore\n",
        "f, ((ax1, ax2)) = plt.subplots(1, 2)\n",
        "cmap = plt.cm.coolwarm\n",
        "\n",
        "by_credit_score = df.groupby(['year', 'grade']).loan_amount.mean()\n",
        "by_credit_score.unstack().plot(legend=False, ax=ax1, figsize=(14, 4), colormap=cmap)\n",
        "ax1.set_title('Loans issued by Credit Score', fontsize=14)\n",
        "\n",
        "\n",
        "by_inc = df.groupby(['year', 'grade']).interest_rate.mean()\n",
        "by_inc.unstack().plot(ax=ax2, figsize=(14, 4), colormap=cmap)\n",
        "ax2.set_title('Interest Rates by Credit Score', fontsize=14)\n",
        "\n",
        "ax2.legend(bbox_to_anchor=(-1.0, -0.3, 1.7, 0.1), loc=5, prop={'size':12},\n",
        "           ncol=7, mode=\"expand\", borderaxespad=0.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d9d859fd942b7ed538a680a2fbe0cc05c997cc50",
        "_cell_guid": "ba20dded-74a0-48de-bc66-1530abdd7cb2",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "zRzlh1LiCNYh"
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,12))\n",
        "\n",
        "ax1 = fig.add_subplot(221)\n",
        "ax2 = fig.add_subplot(222)\n",
        "ax3 = fig.add_subplot(212)\n",
        "\n",
        "cmap = plt.cm.coolwarm_r\n",
        "\n",
        "loans_by_region = df.groupby(['grade', 'loan_condition']).size()\n",
        "loans_by_region.unstack().plot(kind='bar', stacked=True, colormap=cmap, ax=ax1, grid=False)\n",
        "ax1.set_title('Type of Loans by Grade', fontsize=14)\n",
        "\n",
        "\n",
        "loans_by_grade = df.groupby(['sub_grade', 'loan_condition']).size()\n",
        "loans_by_grade.unstack().plot(kind='bar', stacked=True, colormap=cmap, ax=ax2, grid=False)\n",
        "ax2.set_title('Type of Loans by Sub-Grade', fontsize=14)\n",
        "\n",
        "by_interest = df.groupby(['year', 'loan_condition']).interest_rate.mean()\n",
        "by_interest.unstack().plot(ax=ax3, colormap=cmap)\n",
        "ax3.set_title('Average Interest rate by Loan Condition', fontsize=14)\n",
        "ax3.set_ylabel('Interest Rate (%)', fontsize=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5a63504f01a6e3e7088f57138754724e166b4d7e",
        "_cell_guid": "265914e0-b326-4b6c-8cad-a55ebce491b7",
        "id": "KbnZ5SxMCNYi"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>What Determines a Bad Loan </h2>\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "ce76bb007c77bf64c91ef010f11c8f5a49aa8817",
        "_cell_guid": "19a36a8e-0863-45a2-9d31-5e71a038aff5",
        "trusted": true,
        "id": "vbGclYNgCNYi"
      },
      "cell_type": "code",
      "source": [
        "# Just get me the numeric variables\n",
        "numeric_variables = df.select_dtypes(exclude=[\"object\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "562f902591f808328462b310066571f8e2f0a0e5",
        "_cell_guid": "8084478f-0d2d-4922-87a3-f6fd002465da",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "ouFEwu0eCNYi"
      },
      "cell_type": "code",
      "source": [
        "# We will use df_correlations dataframe to analyze our correlations.\n",
        "\n",
        "\n",
        "df_correlations = df.corr()\n",
        "\n",
        "\n",
        "trace = go.Heatmap(z=df_correlations.values,\n",
        "                   x=df_correlations.columns,\n",
        "                   y=df_correlations.columns,\n",
        "                  colorscale=[[0.0, 'rgb(165,0,38)'],\n",
        "                              [0.1111111111111111, 'rgb(215,48,39)'],\n",
        "                              [0.2222222222222222, 'rgb(244,109,67)'],\n",
        "                              [0.3333333333333333, 'rgb(253,174,97)'],\n",
        "                              [0.4444444444444444, 'rgb(254,224,144)'],\n",
        "                              [0.5555555555555556, 'rgb(224,243,248)'],\n",
        "                              [0.6666666666666666, 'rgb(171,217,233)'],\n",
        "                              [0.7777777777777778, 'rgb(116,173,209)'],\n",
        "                              [0.8888888888888888, 'rgb(69,117,180)'],\n",
        "                              [1.0, 'rgb(49,54,149)']],\n",
        "            colorbar = dict(\n",
        "            title = 'Level of Correlation',\n",
        "            titleside = 'top',\n",
        "            tickmode = 'array',\n",
        "            tickvals = [-0.52,0.2,0.95],\n",
        "            ticktext = ['Negative Correlation','Low Correlation','Positive Correlation'],\n",
        "            ticks = 'outside'\n",
        "        )\n",
        "                  )\n",
        "\n",
        "\n",
        "layout = {\"title\": \"Correlation Heatmap\"}\n",
        "data=[trace]\n",
        "\n",
        "fig = dict(data=data, layout=layout)\n",
        "iplot(fig, filename='labelled-heatmap')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "93234728cf730963285429c2ae2a4a610e0c5588",
        "_cell_guid": "1ac9ade7-50ca-413b-a3a4-f0024c2a7005",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "VbV3R1YXCNYj"
      },
      "cell_type": "code",
      "source": [
        "title = 'Bad Loans: Loan Statuses'\n",
        "\n",
        "labels = bad_loan # All the elements that comprise a bad loan.\n",
        "\n",
        "len(labels)\n",
        "colors = ['rgba(236, 112, 99, 1)', 'rgba(235, 152, 78, 1)', 'rgba(52, 73, 94, 1)', 'rgba(128, 139, 150, 1)',\n",
        "         'rgba(255, 87, 51, 1)', 'rgba(255, 195, 0, 1)']\n",
        "\n",
        "mode_size = [8,8,8,8,8,8]\n",
        "\n",
        "line_size = [2,2,2,2,2,2]\n",
        "\n",
        "x_data = [\n",
        "    sorted(df['year'].unique().tolist()),\n",
        "    sorted(df['year'].unique().tolist()),\n",
        "    sorted(df['year'].unique().tolist()),\n",
        "    sorted(df['year'].unique().tolist()),\n",
        "    sorted(df['year'].unique().tolist()),\n",
        "    sorted(df['year'].unique().tolist()),\n",
        "]\n",
        "\n",
        "# type of loans\n",
        "charged_off = df['loan_amount'].loc[df['loan_status'] == 'Charged Off'].values.tolist()\n",
        "defaults = df['loan_amount'].loc[df['loan_status'] == 'Default'].values.tolist()\n",
        "not_credit_policy = df['loan_amount'].loc[df['loan_status'] == 'Does not meet the credit policy. Status:Charged Off'].values.tolist()\n",
        "grace_period = df['loan_amount'].loc[df['loan_status'] == 'In Grace Period'].values.tolist()\n",
        "short_late = df['loan_amount'].loc[df['loan_status'] == 'Late (16-30 days)'].values.tolist()\n",
        "long_late = df['loan_amount'].loc[df['loan_status'] == 'Late (31-120 days)'].values.tolist()\n",
        "\n",
        "y_data = [\n",
        "    charged_off,\n",
        "    defaults,\n",
        "    not_credit_policy,\n",
        "    grace_period,\n",
        "    short_late,\n",
        "    long_late,\n",
        "]\n",
        "\n",
        "p_charged_off = go.Scatter(\n",
        "    x = x_data[0],\n",
        "    y = y_data[0],\n",
        "    name = 'A. Charged Off',\n",
        "    line = dict(\n",
        "        color = colors[0],\n",
        "        width = 3,\n",
        "        dash='dash')\n",
        ")\n",
        "\n",
        "p_defaults = go.Scatter(\n",
        "    x = x_data[1],\n",
        "    y = y_data[1],\n",
        "    name = 'A. Defaults',\n",
        "    line = dict(\n",
        "        color = colors[1],\n",
        "        width = 3,\n",
        "        dash='dash')\n",
        ")\n",
        "\n",
        "p_credit_policy = go.Scatter(\n",
        "    x = x_data[2],\n",
        "    y = y_data[2],\n",
        "    name = 'Not Meet C.P',\n",
        "    line = dict(\n",
        "        color = colors[2],\n",
        "        width = 3,\n",
        "        dash='dash')\n",
        ")\n",
        "\n",
        "p_graced = go.Scatter(\n",
        "    x = x_data[3],\n",
        "    y = y_data[3],\n",
        "    name = 'A. Graced Period',\n",
        "    line = dict(\n",
        "        color = colors[3],\n",
        "        width = 3,\n",
        "        dash='dash')\n",
        ")\n",
        "\n",
        "p_short_late = go.Scatter(\n",
        "    x = x_data[4],\n",
        "    y = y_data[4],\n",
        "    name = 'Late (16-30 days)',\n",
        "    line = dict(\n",
        "        color = colors[4],\n",
        "        width = 3,\n",
        "        dash='dash')\n",
        ")\n",
        "\n",
        "p_long_late = go.Scatter(\n",
        "    x = x_data[5],\n",
        "    y = y_data[5],\n",
        "    name = 'Late (31-120 days)',\n",
        "    line = dict(\n",
        "        color = colors[5],\n",
        "        width = 3,\n",
        "        dash='dash')\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data=[p_charged_off, p_defaults, p_credit_policy, p_graced, p_short_late, p_long_late]\n",
        "\n",
        "layout = dict(title = 'Types of Bad Loans <br> (Amount Borrowed Throughout the Years)',\n",
        "              xaxis = dict(title = 'Year'),\n",
        "              yaxis = dict(title = 'Amount Issued'),\n",
        "              )\n",
        "\n",
        "fig = dict(data=data, layout=layout)\n",
        "\n",
        "iplot(fig, filename='line-mode')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9f4988abfc9615bf59f35044c3b03aa75ab21126",
        "_cell_guid": "fa9e904b-b8be-4e54-b260-415497101239",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "a95KI40_CNYk"
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(18,18))\n",
        "\n",
        "# Create a dataframe for bad loans\n",
        "bad_df = df.loc[df['loan_condition'] == 'Bad Loan']\n",
        "\n",
        "plt.subplot(211)\n",
        "g = sns.boxplot(x='home_ownership', y='loan_amount', hue='loan_condition',\n",
        "               data=bad_df, color='r')\n",
        "\n",
        "g.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
        "g.set_xlabel(\"Type of Home Ownership\", fontsize=12)\n",
        "g.set_ylabel(\"Loan Amount\", fontsize=12)\n",
        "g.set_title(\"Distribution of Amount Borrowed \\n by Home Ownership\", fontsize=16)\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(212)\n",
        "g1 = sns.boxplot(x='year', y='loan_amount', hue='home_ownership',\n",
        "               data=bad_df, palette=\"Set3\")\n",
        "g1.set_xticklabels(g1.get_xticklabels(),rotation=45)\n",
        "g1.set_xlabel(\"Type of Home Ownership\", fontsize=12)\n",
        "g1.set_ylabel(\"Loan Amount\", fontsize=12)\n",
        "g1.set_title(\"Distribution of Amount Borrowed \\n through the years\", fontsize=16)\n",
        "\n",
        "\n",
        "plt.subplots_adjust(hspace = 0.6, top = 0.8)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fa94049d344e0cd0407274ff094fd28302b4cd73",
        "_cell_guid": "9cbebcdb-0445-44dd-960c-c4dbc734929c",
        "id": "ytRlSzTaCNYk"
      },
      "cell_type": "markdown",
      "source": [
        "## Defaulted Loans and Level of Risk:\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "3ebf01c55a68109fca1194f13c7eabb6e6d2bd23",
        "_cell_guid": "21cefe96-b94e-4fc9-966d-7b7e84b23f1e",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "p9eUg-f3CNYl"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Get the loan amount for loans that were defaulted by each region.\n",
        "northe_defaults = df['loan_amount'].loc[(df['region'] == 'NorthEast') & (df['loan_status'] == 'Default')].values.tolist()\n",
        "southw_defaults = df['loan_amount'].loc[(df['region'] == 'SouthWest') & (df['loan_status'] == 'Default')].values.tolist()\n",
        "southe_defaults = df['loan_amount'].loc[(df['region'] == 'SouthEast') & (df['loan_status'] == 'Default')].values.tolist()\n",
        "west_defaults = df['loan_amount'].loc[(df['region'] == 'West') & (df['loan_status'] == 'Default')].values.tolist()\n",
        "midw_defaults = df['loan_amount'].loc[(df['region'] == 'MidWest') & (df['loan_status'] == 'Default')].values.tolist()\n",
        "\n",
        "# Cumulative Values\n",
        "y0_stck=northe_defaults\n",
        "y1_stck=[y0+y1 for y0, y1 in zip(northe_defaults, southw_defaults)]\n",
        "y2_stck=[y0+y1+y2 for y0, y1, y2 in zip(northe_defaults, southw_defaults, southe_defaults)]\n",
        "y3_stck=[y0+y1+y2+y3 for y0, y1, y2, y3 in zip(northe_defaults, southw_defaults, southe_defaults, west_defaults)]\n",
        "y4_stck=[y0+y1+y2+y3+y4 for y0, y1, y2, y3, y4 in zip(northe_defaults, southw_defaults, southe_defaults, west_defaults, midw_defaults)]\n",
        "\n",
        "# Make original values strings and add % for hover text\n",
        "y0_txt=['$' + str(y0) for y0 in northe_defaults]\n",
        "y1_txt=['$' + str(y1) for y1 in southw_defaults]\n",
        "y2_txt=['$' + str(y2) for y2 in southe_defaults]\n",
        "y3_txt=['$' + str(y3) for y3 in west_defaults]\n",
        "y4_txt=['$'+ str(y4) for y4 in midw_defaults]\n",
        "\n",
        "year = sorted(df[\"year\"].unique().tolist())\n",
        "\n",
        "NorthEast_defaults = go.Scatter(\n",
        "    x= year,\n",
        "    y= y0_stck,\n",
        "    text=y0_txt,\n",
        "    hoverinfo='x+text',\n",
        "    name='NorthEast',\n",
        "    mode= 'lines',\n",
        "    line=dict(width=0.5,\n",
        "             color='rgb(131, 90, 241)'),\n",
        "    fill='tonexty'\n",
        ")\n",
        "SouthWest_defaults = go.Scatter(\n",
        "    x=year,\n",
        "    y=y1_stck,\n",
        "    text=y1_txt,\n",
        "    hoverinfo='x+text',\n",
        "    name='SouthWest',\n",
        "    mode= 'lines',\n",
        "    line=dict(width=0.5,\n",
        "             color='rgb(255, 140, 0)'),\n",
        "    fill='tonexty'\n",
        ")\n",
        "\n",
        "SouthEast_defaults = go.Scatter(\n",
        "    x= year,\n",
        "    y= y2_stck,\n",
        "    text=y2_txt,\n",
        "    hoverinfo='x+text',\n",
        "    name='SouthEast',\n",
        "    mode= 'lines',\n",
        "    line=dict(width=0.5,\n",
        "             color='rgb(240, 128, 128)'),\n",
        "    fill='tonexty'\n",
        ")\n",
        "\n",
        "West_defaults = go.Scatter(\n",
        "    x= year,\n",
        "    y= y3_stck,\n",
        "    text=y3_txt,\n",
        "    hoverinfo='x+text',\n",
        "    name='West',\n",
        "    mode= 'lines',\n",
        "    line=dict(width=0.5,\n",
        "             color='rgb(135, 206, 235)'),\n",
        "    fill='tonexty'\n",
        ")\n",
        "\n",
        "MidWest_defaults = go.Scatter(\n",
        "    x= year,\n",
        "    y= y4_stck,\n",
        "    text=y4_txt,\n",
        "    hoverinfo='x+text',\n",
        "    name='MidWest',\n",
        "    mode= 'lines',\n",
        "    line=dict(width=0.5,\n",
        "             color='rgb(240, 230, 140)'),\n",
        "    fill='tonexty'\n",
        "    )\n",
        "\n",
        "\n",
        "data = [NorthEast_defaults, SouthWest_defaults, SouthEast_defaults, West_defaults, MidWest_defaults]\n",
        "\n",
        "layout = dict(title = 'Amount Defaulted by Region',\n",
        "              xaxis = dict(title = 'Year'),\n",
        "              yaxis = dict(title = 'Amount Defaulted')\n",
        "             )\n",
        "\n",
        "fig = dict(data=data, layout=layout)\n",
        "\n",
        "iplot(fig, filename='basic-area-no-bound')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0b92e46f6497e3879c38341e03f12725bf5a9957",
        "_cell_guid": "a054995e-1b03-4ebf-bf0d-f1e73c3bc4d0",
        "id": "4kKUcdaYCNYl"
      },
      "cell_type": "markdown",
      "source": []
    },
    {
      "metadata": {
        "_uuid": "1b66129c72b78775afad04857630c908089a7ca9",
        "_cell_guid": "04332c5a-48ad-4b93-8925-a658dce50e40",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "3QhafNPpCNYm"
      },
      "cell_type": "code",
      "source": [
        "df['interest_rate'].describe()\n",
        "# Average interest is 13.26% Anything above this will be considered of high risk let's see if this is true.\n",
        "df['interest_payments'] = np.nan\n",
        "lst = [df]\n",
        "\n",
        "for col in lst:\n",
        "    col.loc[col['interest_rate'] <= 13.23, 'interest_payments'] = 'Low'\n",
        "    col.loc[col['interest_rate'] > 13.23, 'interest_payments'] = 'High'\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "248f8252aaa9e0024e6a57f59a58d44430808a00",
        "_cell_guid": "6afd4368-f754-40f0-9e4d-cbda61ebbabe",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "4QhkIzCVCNYm"
      },
      "cell_type": "code",
      "source": [
        "df['term'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dea4755d7bcfadfdca96f1adbeb94d44d3386b00",
        "_cell_guid": "9ef845e2-3cc9-489f-a5d1-4e43d0726a4b",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "SCi2aFZbCNYn"
      },
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "palette = ['#009393', '#930000']\n",
        "plt.subplot(221)\n",
        "ax = sns.countplot(x='interest_payments', data=df,\n",
        "                  palette=palette, hue='loan_condition')\n",
        "\n",
        "ax.set_title('The impact of interest rate \\n on the condition of the loan', fontsize=14)\n",
        "ax.set_xlabel('Level of Interest Payments', fontsize=12)\n",
        "ax.set_ylabel('Count')\n",
        "\n",
        "plt.subplot(222)\n",
        "ax1 = sns.countplot(x='interest_payments', data=df,\n",
        "                   palette=palette, hue='term')\n",
        "\n",
        "ax1.set_title('The impact of maturity date \\n on interest rates', fontsize=14)\n",
        "ax1.set_xlabel('Level of Interest Payments', fontsize=12)\n",
        "ax1.set_ylabel('Count')\n",
        "\n",
        "\n",
        "plt.subplot(212)\n",
        "low = df['loan_amount'].loc[df['interest_payments'] == 'Low'].values\n",
        "high = df['loan_amount'].loc[df['interest_payments'] == 'High'].values\n",
        "\n",
        "\n",
        "ax2= sns.distplot(low, color='#009393', label='Low Interest Payments', fit=norm, fit_kws={\"color\":\"#483d8b\"}) # Dark Blue Norm Color\n",
        "ax3 = sns.distplot(high, color='#930000', label='High Interest Payments', fit=norm, fit_kws={\"color\":\"#c71585\"}) #  Red Norm Color\n",
        "plt.axis([0, 36000, 0, 0.00016])\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "70536045c4c088b23e82cde2d7643d4289adb0f9",
        "_cell_guid": "aa0fd7e2-870d-401d-96e5-a7c504157872",
        "id": "8vg7OwiNCNYn"
      },
      "cell_type": "markdown",
      "source": [
        "## Risk Assesment:\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "c02adf19c2c71e052cbe3aeab7d8bd6663ef289d",
        "_cell_guid": "ba05f3a3-af80-496c-817a-35a34cbfe7bc",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "YEoqUIhaCNYn"
      },
      "cell_type": "code",
      "source": [
        "import plotly.plotly as py\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "# Interest rate good loans\n",
        "avg_fully_paid = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'Fully Paid'].values), 2)\n",
        "avg_current = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'Current'].values), 2)\n",
        "avg_issued = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'Issued'].values), 2)\n",
        "avg_long_fully_paid = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'Does not meet the credit policy. Status:Fully Paid'].values), 2)\n",
        "\n",
        "\n",
        "\n",
        "# Interest rate bad loans\n",
        "\n",
        "avg_default_rates = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'Default'].values), 2)\n",
        "avg_charged_off = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'Charged Off'].values), 2)\n",
        "avg_long_charged_off = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'Does not meet the credit policy. Status:Charged Off'].values), 2)\n",
        "avg_grace_period = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'In Grace Period'].values), 2)\n",
        "avg_short_late = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'Late (16-30 days)'].values), 2)\n",
        "avg_long_late = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'Late (31-120 days)'].values), 2)\n",
        "\n",
        "\n",
        "# Take to a dataframe\n",
        "\n",
        "data = [\n",
        "    go.Scatterpolar(\n",
        "        mode='lines+markers',\n",
        "      r = [avg_fully_paid, avg_current, avg_issued, avg_long_fully_paid],\n",
        "      theta = ['Fully Paid', 'Current', 'Issued', 'No C.P. Fully Paid'],\n",
        "      fill = 'toself',\n",
        "      name = 'Good Loans',\n",
        "        line = dict(\n",
        "        color = \"#63AF63\"\n",
        "      ),\n",
        "      marker = dict(\n",
        "        color = \"#B3FFB3\",\n",
        "        symbol = \"square\",\n",
        "        size = 8\n",
        "      ),\n",
        "      subplot = \"polar\",\n",
        "    ),\n",
        "    go.Scatterpolar(\n",
        "        mode='lines+markers',\n",
        "      r = [avg_default_rates, avg_charged_off, avg_long_charged_off, avg_grace_period, avg_short_late, avg_long_late],\n",
        "      theta = ['Default Rate', 'Charged Off', 'C.P. Charged Off', 'In Grace Period', 'Late (16-30 days)', 'Late (31-120 days)'],\n",
        "      fill = 'toself',\n",
        "      name = 'Bad Loans',\n",
        "        line = dict(\n",
        "        color = \"#C31414\"\n",
        "      ),\n",
        "      marker = dict(\n",
        "        color = \"#FF5050\",\n",
        "        symbol = \"square\",\n",
        "        size = 8\n",
        "      ),\n",
        "      subplot = \"polar2\"\n",
        "    )\n",
        "]\n",
        "\n",
        "layout = go.Layout(\n",
        "    title=\"Average Interest Rates <br> Loan Status Distribution\",\n",
        "    showlegend = False,\n",
        "     paper_bgcolor = \"rgb(255, 248, 243)\",\n",
        "    polar = dict(\n",
        "      domain = dict(\n",
        "        x = [0,0.4],\n",
        "        y = [0,1]\n",
        "      ),\n",
        "      radialaxis = dict(\n",
        "        tickfont = dict(\n",
        "          size = 8\n",
        "        )\n",
        "      ),\n",
        "      angularaxis = dict(\n",
        "        tickfont = dict(\n",
        "          size = 8\n",
        "        ),\n",
        "        rotation = 90,\n",
        "        direction = \"counterclockwise\"\n",
        "      )\n",
        "    ),\n",
        "    polar2 = dict(\n",
        "      domain = dict(\n",
        "        x = [0.6,1],\n",
        "        y = [0,1]\n",
        "      ),\n",
        "      radialaxis = dict(\n",
        "        tickfont = dict(\n",
        "          size = 8\n",
        "        )\n",
        "      ),\n",
        "      angularaxis = dict(\n",
        "        tickfont = dict(\n",
        "          size = 8\n",
        "        ),\n",
        "        rotation = 90,\n",
        "        direction = \"clockwise\"\n",
        "      ),\n",
        "    )\n",
        ")\n",
        "\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "iplot(fig, filename='polar/directions')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9098a5bb015b266239063777b19f5f2e96dca2c8",
        "_cell_guid": "8189c32f-bca9-4352-8970-ac3a2105f08d",
        "id": "hTLmighPCNYo"
      },
      "cell_type": "markdown",
      "source": [
        "## Condition of Loans and Purpose:\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "52ff33526a8be8df1bf1f05b351e0af03109bb7d",
        "_cell_guid": "9d3f0eb2-7972-4530-ba4a-7dc972365532",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "_iex4GQUCNYo"
      },
      "cell_type": "code",
      "source": [
        "df['purpose'].value_counts()\n",
        "\n",
        "# Education, renewable energy, wedding are the purposed that contains highest bad loans percent wise.\n",
        "\n",
        "purpose_condition = round(pd.crosstab(df['loan_condition'], df['purpose']).apply(lambda x: x/x.sum() * 100), 2)\n",
        "\n",
        "purpose_bad_loans = purpose_condition.values[0].tolist()\n",
        "purpose_good_loans = purpose_condition.values[1].tolist()\n",
        "purpose = purpose_condition.columns\n",
        "\n",
        "\n",
        "bad_plot = go.Bar(\n",
        "    x=purpose,\n",
        "    y=purpose_bad_loans,\n",
        "    name = 'Bad Loans',\n",
        "    text='%',\n",
        "    marker=dict(\n",
        "        color='rgba(219, 64, 82, 0.7)',\n",
        "        line = dict(\n",
        "            color='rgba(219, 64, 82, 1.0)',\n",
        "            width=2\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "good_plot = go.Bar(\n",
        "    x=purpose,\n",
        "    y=purpose_good_loans,\n",
        "    name='Good Loans',\n",
        "    text='%',\n",
        "    marker=dict(\n",
        "        color='rgba(50, 171, 96, 0.7)',\n",
        "        line = dict(\n",
        "            color='rgba(50, 171, 96, 1.0)',\n",
        "            width=2\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "data = [bad_plot, good_plot]\n",
        "\n",
        "layout = go.Layout(\n",
        "    title='Condition of Loan by Purpose',\n",
        "    xaxis=dict(\n",
        "        title=''\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        title='% of the Loan',\n",
        "    ),\n",
        "    paper_bgcolor='#FFF8DC',\n",
        "    plot_bgcolor='#FFF8DC',\n",
        "    showlegend=True\n",
        ")\n",
        "\n",
        "fig = dict(data=data, layout=layout)\n",
        "iplot(fig, filename='condition_purposes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2638cba0e0a790a96cda92a2bc17cb0071624bbd",
        "_cell_guid": "7ba370f2-b2ff-41ae-a4e4-00fd77f73a80",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "s8pvIgD4CNYo"
      },
      "cell_type": "code",
      "source": [
        "# Average interest by income category and purposes\n",
        "# Which purpose carries a higher interest rate and does income category have an influence on risk?\n",
        "# Is LendingClub deploying loan amount where there is a high risk (interest_rate)\n",
        "# Remember we learned that interest_rates is a key metric in evaluating risk.\n",
        "\n",
        "\n",
        "\n",
        "group_income_purpose = df.groupby(['income_category', 'purpose'], as_index=False).interest_rate.mean()\n",
        "group_dti_purpose = df.groupby(['income_category', 'purpose'], as_index=False).loan_amount.mean()\n",
        "loan_a = group_dti_purpose['loan_amount'].values\n",
        "\n",
        "\n",
        "\n",
        "# High Car 10.32 15669\n",
        "new_groupby = group_income_purpose.assign(total_loan_amount=loan_a)\n",
        "sort_group_income_purpose = new_groupby.sort_values(by=\"income_category\", ascending=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "24b878001ff17e42f066f6bc838c19f2990b4af5",
        "_cell_guid": "cb2f9647-973d-4dd3-8300-b397f0a8d23e",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "NsouvqWsCNYp"
      },
      "cell_type": "code",
      "source": [
        "loan_count = df.groupby(['income_category', 'purpose'])['loan_condition'].apply(lambda x: x.value_counts())\n",
        "d={\"loan_c\": loan_count}\n",
        "loan_c_df = pd.DataFrame(data=d).reset_index()\n",
        "loan_c_df = loan_c_df.rename(columns={\"level_2\": \"loan_condition\"})\n",
        "\n",
        "\n",
        "# Good loans & Bad Loans\n",
        "good_loans = loan_c_df.loc[loan_c_df['loan_condition'] == \"Good Loan\"].sort_values(by=\"income_category\", ascending=True)\n",
        "bad_loans = loan_c_df.loc[loan_c_df['loan_condition'] == \"Bad Loan\"].sort_values(by=\"income_category\", ascending=True)\n",
        "sort_group_income_purpose['good_loans_count'] = good_loans['loan_c'].values\n",
        "sort_group_income_purpose['bad_loans_count'] = bad_loans['loan_c'].values\n",
        "sort_group_income_purpose['total_loans_issued'] = (good_loans['loan_c'].values + bad_loans['loan_c'].values)\n",
        "sort_group_income_purpose['bad/good ratio (%)'] = np.around(bad_loans['loan_c'].values / (bad_loans['loan_c'].values + good_loans['loan_c'].values), 4) * 100\n",
        "final_df = sort_group_income_purpose.sort_values(by='income_category', ascending=True)\n",
        "final_df.style.background_gradient('coolwarm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "712f0414c0383e9bd13b23e75277cc4da71c758b",
        "_kg_hide-input": true,
        "id": "OSbkF3UiCNYp"
      },
      "cell_type": "code",
      "source": [
        "final_df = final_df.sort_values(by=\"purpose\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "51a0211b7167f3db6125376369f2a11273103b19",
        "_kg_hide-input": true,
        "id": "3WOZ2hWhCNYp"
      },
      "cell_type": "code",
      "source": [
        "# Work on a plot to explain better the correlations between the different columns in final_df dataframe.\n",
        "# We will do a Subplot in Plotly with\n",
        "\n",
        "import plotly.plotly as py\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "# Labels\n",
        "purpose_labels = df['purpose'].unique()\n",
        "\n",
        "# Average Interest Rate Dot Plots # 1st Subplot\n",
        "high_income = final_df['interest_rate'].loc[final_df['income_category'] == 'High'].values.tolist()\n",
        "medium_income = final_df['interest_rate'].loc[final_df['income_category'] == 'Medium'].values.tolist()\n",
        "low_income = final_df['interest_rate'].loc[final_df['income_category'] == 'Low'].values.tolist()\n",
        "\n",
        "high_lst = ['%.2f' % val for val in high_income]\n",
        "med_lst = ['%.2f' % val for val in medium_income]\n",
        "low_lst = ['%.2f' % val for val in low_income]\n",
        "\n",
        "\n",
        "\n",
        "trace1 = {\"x\": high_lst,\n",
        "          \"y\": purpose_labels,\n",
        "          \"marker\": {\"color\": \"#0040FF\", \"size\": 16},\n",
        "          \"mode\": \"markers\",\n",
        "          \"name\": \"High Income\",\n",
        "          \"type\": \"scatter\"\n",
        "}\n",
        "\n",
        "trace2 = {\"x\": med_lst,\n",
        "          \"y\": purpose_labels,\n",
        "          \"marker\": {\"color\": \"#FE9A2E\", \"size\": 16},\n",
        "          \"mode\": \"markers\",\n",
        "          \"name\": \"Medium Income\",\n",
        "          \"type\": \"scatter\",\n",
        "}\n",
        "\n",
        "trace3 = {\"x\": low_lst,\n",
        "          \"y\": purpose_labels,\n",
        "          \"marker\": {\"color\": \"#FE2E2E\", \"size\": 16},\n",
        "          \"mode\": \"markers\",\n",
        "          \"name\": \"Low Income\",\n",
        "          \"type\": \"scatter\",\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = [trace1, trace2, trace3]\n",
        "layout = {\"title\": \"Average Purpose Interest Rate <br> <i> by Income Category </i> \",\n",
        "          \"xaxis\": {\"title\": \"Average Interest Rate\", },\n",
        "          \"yaxis\": {\"title\": \"\"}}\n",
        "\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "iplot(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "afcd4c0aa4bcb61eb234c0b3f7e9eaf843064d83",
        "_kg_hide-input": true,
        "id": "w3lMi0j2CNYp"
      },
      "cell_type": "code",
      "source": [
        "# Labels\n",
        "purpose_labels = final_df['purpose'].unique()\n",
        "\n",
        "# Amount of Good and Bad Loans per Purpose (fill by income category)\n",
        "# Good Loans\n",
        "good_high_cnt = final_df['good_loans_count'].loc[final_df['income_category'] == \"High\"].values.tolist()\n",
        "good_med_cnt = final_df['good_loans_count'].loc[final_df['income_category'] == \"Medium\"].values.tolist()\n",
        "good_low_cnt = final_df['good_loans_count'].loc[final_df['income_category'] == \"Low\"].values.tolist()\n",
        "\n",
        "# Bad Loans\n",
        "bad_high_cnt = final_df['bad_loans_count'].loc[final_df['income_category'] == \"High\"].values.tolist()\n",
        "bad_med_cnt = final_df['bad_loans_count'].loc[final_df['income_category'] == \"Medium\"].values.tolist()\n",
        "bad_low_cnt = final_df['bad_loans_count'].loc[final_df['income_category'] == \"Low\"].values.tolist()\n",
        "\n",
        "\n",
        "# Good Loans\n",
        "trace0 = go.Bar(\n",
        "    y=purpose_labels,\n",
        "    x=good_high_cnt,\n",
        "    legendgroup='a',\n",
        "    name='High Income',\n",
        "    orientation='h',\n",
        "    marker=dict(\n",
        "        color='#0040FF'\n",
        "    )\n",
        ")\n",
        "trace1 = go.Bar(\n",
        "    x=good_med_cnt,\n",
        "    y=purpose_labels,\n",
        "    legendgroup='a',\n",
        "    name='Medium Income',\n",
        "    orientation='h',\n",
        "    marker=dict(\n",
        "        color='#FE9A2E',\n",
        "    )\n",
        ")\n",
        "\n",
        "trace2 = go.Bar(\n",
        "    x=good_low_cnt,\n",
        "    y=purpose_labels,\n",
        "    legendgroup='a',\n",
        "    name='Low Income',\n",
        "    orientation='h',\n",
        "    marker=dict(\n",
        "        color='#FE2E2E',\n",
        "    )\n",
        ")\n",
        "\n",
        "# Bad Loans issued by Income Category\n",
        "trace3 = go.Bar(\n",
        "    y=purpose_labels,\n",
        "    x=bad_high_cnt,\n",
        "    legendgroup='b',\n",
        "    showlegend=False,\n",
        "    name='High Income',\n",
        "    orientation='h',\n",
        "    marker=dict(\n",
        "        color='#0040FF'\n",
        "    )\n",
        ")\n",
        "trace4 = go.Bar(\n",
        "    x=bad_med_cnt,\n",
        "    y=purpose_labels,\n",
        "    legendgroup='b',\n",
        "    showlegend=False,\n",
        "    name='Medium Income',\n",
        "    orientation='h',\n",
        "    marker=dict(\n",
        "        color='#FE9A2E',\n",
        "    )\n",
        ")\n",
        "\n",
        "trace5 = go.Bar(\n",
        "    x=bad_low_cnt,\n",
        "    y=purpose_labels,\n",
        "    legendgroup='b',\n",
        "    showlegend=False,\n",
        "    name='Low Income',\n",
        "    orientation='h',\n",
        "    marker=dict(\n",
        "        color='#FE2E2E',\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "fig = tools.make_subplots(rows=2, cols=1, print_grid=False,\n",
        "                         subplot_titles=(\"Amount of <br> <i>Good Loans Issued</i>\",\n",
        "                                        \"Amount of <br> <i>Bad Loans Issued</i>\")\n",
        "                         )\n",
        "\n",
        "# First Subplot\n",
        "fig.append_trace(trace0, 1, 1)\n",
        "fig.append_trace(trace1, 1, 1)\n",
        "fig.append_trace(trace2, 1, 1)\n",
        "\n",
        "# Second Subplot\n",
        "fig.append_trace(trace3, 2, 1)\n",
        "fig.append_trace(trace4, 2, 1)\n",
        "fig.append_trace(trace5, 2, 1)\n",
        "\n",
        "fig['layout'].update(height=800, width=800, title='Issuance of Loans', showlegend=True, xaxis=dict(title=\"Number of Loans Issued\"))\n",
        "iplot(fig, filename='angled-text-bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "a52a906925bf332dca15f1bbd4f2ce1463f90e0c",
        "id": "Hfczd6RiCNYp"
      },
      "cell_type": "code",
      "source": [
        "# Next task a Radar Chart with the bad/good ratio to see if it justifies the amount of loans issued towards housing\n",
        "high_ratio = final_df.loc[final_df['income_category'] == 'High']\n",
        "medium_ratio = final_df.loc[final_df['income_category'] == 'Medium']\n",
        "low_ratio = final_df.loc[final_df['income_category'] == 'Low']\n",
        "\n",
        "data = [\n",
        "    go.Scatterpolar(\n",
        "        mode='lines+markers',\n",
        "      r = high_ratio['bad/good ratio (%)'].values.tolist(),\n",
        "      theta = high_ratio['purpose'].unique(),\n",
        "      fill = 'toself',\n",
        "      name = 'High Income',\n",
        "        line = dict(\n",
        "        color = \"#63AF63\"\n",
        "      ),\n",
        "      marker = dict(\n",
        "        color = \"#B3FFB3\",\n",
        "        symbol = \"square\",\n",
        "        size = 8\n",
        "      ),\n",
        "      subplot = \"polar\",\n",
        "    ),\n",
        "    go.Scatterpolar(\n",
        "        mode='lines+markers',\n",
        "      r = medium_ratio['bad/good ratio (%)'].values.tolist(),\n",
        "      theta = medium_ratio['purpose'].unique(),\n",
        "      fill = 'toself',\n",
        "      name = 'Medium Income',\n",
        "        line = dict(\n",
        "        color = \"#C31414\"\n",
        "      ),\n",
        "      marker = dict(\n",
        "        color = \"#FF5050\",\n",
        "        symbol = \"square\",\n",
        "        size = 8\n",
        "      ),\n",
        "      subplot = \"polar2\"\n",
        "    ),\n",
        "    go.Scatterpolar(\n",
        "        mode='lines+markers',\n",
        "      r = low_ratio['bad/good ratio (%)'].values.tolist(),\n",
        "      theta = low_ratio['purpose'].unique(),\n",
        "      fill = 'toself',\n",
        "      name = 'Low Income',\n",
        "        line = dict(\n",
        "        color = \"#C9FFC7\"\n",
        "      ),\n",
        "      marker = dict(\n",
        "        color = \"#8CB28B\",\n",
        "        symbol = \"square\",\n",
        "        size = 8\n",
        "      ),\n",
        "      subplot = \"polar3\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "layout = go.Layout(\n",
        "    title=\"Bad/Good Ratio <br> (By Purpose)\",\n",
        "    showlegend = False,\n",
        "     paper_bgcolor = \"rgb(255, 206, 153)\",\n",
        "    polar = dict(\n",
        "      domain = dict(\n",
        "        x = [0,0.3],\n",
        "        y = [0,1]\n",
        "      ),\n",
        "      radialaxis = dict(\n",
        "        tickfont = dict(\n",
        "          size = 6\n",
        "        )\n",
        "      ),\n",
        "      angularaxis = dict(\n",
        "        tickfont = dict(\n",
        "          size = 6\n",
        "        ),\n",
        "        rotation = 90,\n",
        "        direction = \"counterclockwise\"\n",
        "      )\n",
        "    ),\n",
        "    polar2 = dict(\n",
        "      domain = dict(\n",
        "        x = [0.35,0.65],\n",
        "        y = [0,1]\n",
        "      ),\n",
        "      radialaxis = dict(\n",
        "        tickfont = dict(\n",
        "          size = 6\n",
        "        )\n",
        "      ),\n",
        "      angularaxis = dict(\n",
        "        tickfont = dict(\n",
        "          size = 6\n",
        "        ),\n",
        "        rotation = 85,\n",
        "        direction = \"clockwise\"\n",
        "      ),\n",
        "    ),\n",
        "    polar3 = dict(\n",
        "      domain = dict(\n",
        "        x = [0.7, 1],\n",
        "        y = [0,1]\n",
        "      ),\n",
        "      radialaxis = dict(\n",
        "        tickfont = dict(\n",
        "          size = 6\n",
        "        )\n",
        "      ),\n",
        "      angularaxis = dict(\n",
        "        tickfont = dict(\n",
        "          size = 6\n",
        "        ),\n",
        "        rotation = 90,\n",
        "        direction = \"clockwise\"\n",
        "      ),\n",
        "    ))\n",
        "\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "iplot(fig, filename = \"radar/multiple\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b7a23547860a6523e22df9d2ece313c10dc64190",
        "_cell_guid": "86754a74-044f-4a11-99dd-558c698348c8",
        "id": "xEyFhVZbCNYq"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering and Neural Network:\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "2472af317cf864bcdb0faae24af46132607d6bfb",
        "_cell_guid": "a1e68755-64ff-40bc-b8f7-d299ad21f58a",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "OOn5jL25CNYq"
      },
      "cell_type": "code",
      "source": [
        "# Copy Dataframe\n",
        "complete_df = df.copy()\n",
        "\n",
        "\n",
        "# Handling Missing Numeric Values\n",
        "\n",
        "# Transform Missing Values for numeric dataframe\n",
        "# Nevertheless check what these variables mean tomorrow in the morning.\n",
        "for col in ('dti_joint', 'annual_inc_joint', 'il_util', 'mths_since_rcnt_il', 'open_acc_6m', 'open_il_6m', 'open_il_12m',\n",
        "           'open_il_24m', 'inq_last_12m', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'inq_fi', 'total_cu_tl',\n",
        "           'mths_since_last_record', 'mths_since_last_major_derog', 'mths_since_last_delinq', 'total_bal_il', 'tot_coll_amt',\n",
        "           'tot_cur_bal', 'total_rev_hi_lim', 'revol_util', 'collections_12_mths_ex_med', 'open_acc', 'inq_last_6mths',\n",
        "           'verification_status_joint', 'acc_now_delinq'):\n",
        "    complete_df[col] = complete_df[col].fillna(0)\n",
        "\n",
        "\n",
        "\n",
        "# # Get the mode of next payment date and last payment date and the last date credit amount was pulled\n",
        "complete_df[\"next_pymnt_d\"] = complete_df.groupby(\"region\")[\"next_pymnt_d\"].transform(lambda x: x.fillna(x.mode))\n",
        "complete_df[\"last_pymnt_d\"] = complete_df.groupby(\"region\")[\"last_pymnt_d\"].transform(lambda x: x.fillna(x.mode))\n",
        "complete_df[\"last_credit_pull_d\"] = complete_df.groupby(\"region\")[\"last_credit_pull_d\"].transform(lambda x: x.fillna(x.mode))\n",
        "complete_df[\"earliest_cr_line\"] = complete_df.groupby(\"region\")[\"earliest_cr_line\"].transform(lambda x: x.fillna(x.mode))\n",
        "\n",
        "# # Get the mode on the number of accounts in which the client is delinquent\n",
        "complete_df[\"pub_rec\"] = complete_df.groupby(\"region\")[\"pub_rec\"].transform(lambda x: x.fillna(x.median()))\n",
        "\n",
        "# # Get the mean of the annual income depending in the region the client is located.\n",
        "complete_df[\"annual_income\"] = complete_df.groupby(\"region\")[\"annual_income\"].transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        "# Get the mode of the  total number of credit lines the borrower has\n",
        "complete_df[\"total_acc\"] = complete_df.groupby(\"region\")[\"total_acc\"].transform(lambda x: x.fillna(x.median()))\n",
        "\n",
        "# Mode of credit delinquencies in the past two years.\n",
        "complete_df[\"delinq_2yrs\"] = complete_df.groupby(\"region\")[\"delinq_2yrs\"].transform(lambda x: x.fillna(x.mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cfb46ba6476590b51240d45395fdf7448035aa42",
        "_cell_guid": "b59e358a-8beb-4a52-b104-86a1129e6016",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "WqcDM1q3CNYq"
      },
      "cell_type": "code",
      "source": [
        "# Drop these variables before scaling but don't drop these when we perform feature engineering on missing values.\n",
        "# Columns to delete or fix: earliest_cr_line, last_pymnt_d, next_pymnt_d, last_credit_pull_d, verification_status_joint\n",
        "\n",
        "# ---->>>> Fix the problems shown during scaling with the columns above.\n",
        "\n",
        "complete_df.drop(['issue_d', 'income_category', 'region', 'year', 'emp_length', 'loan_condition',\n",
        "                 'earliest_cr_line', 'last_pymnt_d', 'next_pymnt_d', 'last_credit_pull_d',\n",
        "                 'verification_status_joint', 'emp_length_int', 'total_rec_prncp', 'funded_amount', 'investor_funds',\n",
        "                 'sub_grade', 'complete_date', 'loan_status', 'interest_payments',\n",
        "                 'initial_list_status', 'out_prncp', 'out_prncp_inv', 'total_pymnt',\n",
        "               'total_pymnt_inv', 'total_rec_int', 'total_rec_late_fee', 'recoveries',\n",
        "               'collection_recovery_fee', 'last_pymnt_amnt',\n",
        "               'collections_12_mths_ex_med', 'mths_since_last_major_derog',\n",
        "               'policy_code', 'application_type', 'annual_inc_joint', 'dti_joint',\n",
        "               'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m',\n",
        "               'open_il_6m', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il',\n",
        "               'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc',\n",
        "               'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6147c109241c4a9d9a0c67770f4c5294b0408f77",
        "_cell_guid": "e193e220-0dd5-4dae-b081-e825d7e8cff1",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "O3qGHgdqCNYq"
      },
      "cell_type": "code",
      "source": [
        "complete_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "134b552c4c33951fd33fd4f812737d83cfae4df9",
        "_cell_guid": "d03e37e6-35e7-48b6-a7a8-57b515f391a8",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "gClA8ngMCNYr"
      },
      "cell_type": "code",
      "source": [
        "complete_df.isnull().sum().max() # Maximum number of nulls."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "14b2e96a1908af575061200f6bf09d9adcae86ac",
        "_cell_guid": "0615a43e-e8aa-43b8-a7d6-6ccb81d4d1d7",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "BmJHA1VFCNYr"
      },
      "cell_type": "code",
      "source": [
        "# Let's make a copy of the dataframe to avoid confusion.\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.metrics import classification_report_imbalanced\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, StratifiedShuffleSplit\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "len(complete_df['loan_condition_int'])\n",
        "# Loan Ratios (Imbalanced classes)\n",
        "complete_df['loan_condition_int'].value_counts()/len(complete_df['loan_condition_int']) * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "96c13f3db727269c9284b528d1c8c861233f2c74",
        "_cell_guid": "0656a46f-77e9-4a8e-af8f-8b75010d47ba",
        "id": "XwVDsEL2CNYr"
      },
      "cell_type": "markdown",
      "source": [
        "The purpose of the code below is to have the same ratio across our training and test sets."
      ]
    },
    {
      "metadata": {
        "_uuid": "b980cb9a5f4aed482cbb886be2c7ca5d56da7608",
        "_cell_guid": "19d69a00-f76e-4ec2-aced-5da11baedffb",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "p9Ye2a8pCNYr"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "stratified = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "\n",
        "for train_set, test_set in stratified.split(complete_df, complete_df[\"loan_condition_int\"]):\n",
        "    stratified_train = complete_df.loc[train_set]\n",
        "    stratified_test = complete_df.loc[test_set]\n",
        "\n",
        "print('Train set ratio \\n', stratified_train[\"loan_condition_int\"].value_counts()/len(df))\n",
        "print('Test set ratio \\n', stratified_test[\"loan_condition_int\"].value_counts()/len(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "24aa4fc2d8b3458f03519bfdad9e8f84f8286625",
        "_cell_guid": "f1e9321f-4323-4f82-a592-e7a896c30e6a",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "X6GariRMCNYr"
      },
      "cell_type": "code",
      "source": [
        "train_df = stratified_train\n",
        "test_df = stratified_test\n",
        "\n",
        "\n",
        "# Let's Shuffle the data\n",
        "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
        "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "# Train set (Normal training dataset)\n",
        "X_train = train_df.drop('loan_condition_int', axis=1)\n",
        "y_train = train_df['loan_condition_int']\n",
        "\n",
        "\n",
        "# Test Dataset\n",
        "X_test = test_df.drop('loan_condition_int', axis=1)\n",
        "y_test = test_df['loan_condition_int']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a1c1847b7680b8d58db9b6c13ad503bdcb0e23d4",
        "_cell_guid": "a608167e-52ef-4d2a-9f76-6a7c587f5127",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "fvV9OItXCNYr"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.utils import check_array\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy import sparse\n",
        "\n",
        "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Encode categorical features as a numeric array.\n",
        "    The input to this transformer should be a matrix of integers or strings,\n",
        "    denoting the values taken on by categorical (discrete) features.\n",
        "    The features can be encoded using a one-hot aka one-of-K scheme\n",
        "    (``encoding='onehot'``, the default) or converted to ordinal integers\n",
        "    (``encoding='ordinal'``).\n",
        "    This encoding is needed for feeding categorical data to many scikit-learn\n",
        "    estimators, notably linear models and SVMs with the standard kernels.\n",
        "    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n",
        "    Parameters\n",
        "    ----------\n",
        "    encoding : str, 'onehot', 'onehot-dense' or 'ordinal'\n",
        "        The type of encoding to use (default is 'onehot'):\n",
        "        - 'onehot': encode the features using a one-hot aka one-of-K scheme\n",
        "          (or also called 'dummy' encoding). This creates a binary column for\n",
        "          each category and returns a sparse matrix.\n",
        "        - 'onehot-dense': the same as 'onehot' but returns a dense array\n",
        "          instead of a sparse matrix.\n",
        "        - 'ordinal': encode the features as ordinal integers. This results in\n",
        "          a single column of integers (0 to n_categories - 1) per feature.\n",
        "    categories : 'auto' or a list of lists/arrays of values.\n",
        "        Categories (unique values) per feature:\n",
        "        - 'auto' : Determine categories automatically from the training data.\n",
        "        - list : ``categories[i]`` holds the categories expected in the ith\n",
        "          column. The passed categories are sorted before encoding the data\n",
        "          (used categories can be found in the ``categories_`` attribute).\n",
        "    dtype : number type, default np.float64\n",
        "        Desired dtype of output.\n",
        "    handle_unknown : 'error' (default) or 'ignore'\n",
        "        Whether to raise an error or ignore if a unknown categorical feature is\n",
        "        present during transform (default is to raise). When this is parameter\n",
        "        is set to 'ignore' and an unknown category is encountered during\n",
        "        transform, the resulting one-hot encoded columns for this feature\n",
        "        will be all zeros.\n",
        "        Ignoring unknown categories is not supported for\n",
        "        ``encoding='ordinal'``.\n",
        "    Attributes\n",
        "    ----------\n",
        "    categories_ : list of arrays\n",
        "        The categories of each feature determined during fitting. When\n",
        "        categories were specified manually, this holds the sorted categories\n",
        "        (in order corresponding with output of `transform`).\n",
        "    Examples\n",
        "    --------\n",
        "    Given a dataset with three features and two samples, we let the encoder\n",
        "    find the maximum value per feature and transform the data to a binary\n",
        "    one-hot encoding.\n",
        "    >>> from sklearn.preprocessing import CategoricalEncoder\n",
        "    >>> enc = CategoricalEncoder(handle_unknown='ignore')\n",
        "    >>> enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])\n",
        "    ... # doctest: +ELLIPSIS\n",
        "    CategoricalEncoder(categories='auto', dtype=<... 'numpy.float64'>,\n",
        "              encoding='onehot', handle_unknown='ignore')\n",
        "    >>> enc.transform([[0, 1, 1], [1, 0, 4]]).toarray()\n",
        "    array([[ 1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.],\n",
        "           [ 0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
        "    See also\n",
        "    --------\n",
        "    sklearn.preprocessing.OneHotEncoder : performs a one-hot encoding of\n",
        "      integer ordinal features. The ``OneHotEncoder assumes`` that input\n",
        "      features take on values in the range ``[0, max(feature)]`` instead of\n",
        "      using the unique values.\n",
        "    sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of\n",
        "      dictionary items (also handles string-valued features).\n",
        "    sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot\n",
        "      encoding of dictionary items or strings.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoding='onehot', categories='auto', dtype=np.float64,\n",
        "                 handle_unknown='error'):\n",
        "        self.encoding = encoding\n",
        "        self.categories = categories\n",
        "        self.dtype = dtype\n",
        "        self.handle_unknown = handle_unknown\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"Fit the CategoricalEncoder to X.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape [n_samples, n_feature]\n",
        "            The data to determine the categories of each feature.\n",
        "        Returns\n",
        "        -------\n",
        "        self\n",
        "        \"\"\"\n",
        "\n",
        "        if self.encoding not in ['onehot', 'onehot-dense', 'ordinal']:\n",
        "            template = (\"encoding should be either 'onehot', 'onehot-dense' \"\n",
        "                        \"or 'ordinal', got %s\")\n",
        "            raise ValueError(template % self.handle_unknown)\n",
        "\n",
        "        if self.handle_unknown not in ['error', 'ignore']:\n",
        "            template = (\"handle_unknown should be either 'error' or \"\n",
        "                        \"'ignore', got %s\")\n",
        "            raise ValueError(template % self.handle_unknown)\n",
        "\n",
        "        if self.encoding == 'ordinal' and self.handle_unknown == 'ignore':\n",
        "            raise ValueError(\"handle_unknown='ignore' is not supported for\"\n",
        "                             \" encoding='ordinal'\")\n",
        "\n",
        "        X = check_array(X, dtype=np.object, accept_sparse='csc', copy=True)\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        self._label_encoders_ = [LabelEncoder() for _ in range(n_features)]\n",
        "\n",
        "        for i in range(n_features):\n",
        "            le = self._label_encoders_[i]\n",
        "            Xi = X[:, i]\n",
        "            if self.categories == 'auto':\n",
        "                le.fit(Xi)\n",
        "            else:\n",
        "                valid_mask = np.in1d(Xi, self.categories[i])\n",
        "                if not np.all(valid_mask):\n",
        "                    if self.handle_unknown == 'error':\n",
        "                        diff = np.unique(Xi[~valid_mask])\n",
        "                        msg = (\"Found unknown categories {0} in column {1}\"\n",
        "                               \" during fit\".format(diff, i))\n",
        "                        raise ValueError(msg)\n",
        "                le.classes_ = np.array(np.sort(self.categories[i]))\n",
        "\n",
        "        self.categories_ = [le.classes_ for le in self._label_encoders_]\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Transform X using one-hot encoding.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape [n_samples, n_features]\n",
        "            The data to encode.\n",
        "        Returns\n",
        "        -------\n",
        "        X_out : sparse matrix or a 2-d array\n",
        "            Transformed input.\n",
        "        \"\"\"\n",
        "        X = check_array(X, accept_sparse='csc', dtype=np.object, copy=True)\n",
        "        n_samples, n_features = X.shape\n",
        "        X_int = np.zeros_like(X, dtype=np.int)\n",
        "        X_mask = np.ones_like(X, dtype=np.bool)\n",
        "\n",
        "        for i in range(n_features):\n",
        "            valid_mask = np.in1d(X[:, i], self.categories_[i])\n",
        "\n",
        "            if not np.all(valid_mask):\n",
        "                if self.handle_unknown == 'error':\n",
        "                    diff = np.unique(X[~valid_mask, i])\n",
        "                    msg = (\"Found unknown categories {0} in column {1}\"\n",
        "                           \" during transform\".format(diff, i))\n",
        "                    raise ValueError(msg)\n",
        "                else:\n",
        "                    # Set the problematic rows to an acceptable value and\n",
        "                    # continue `The rows are marked `X_mask` and will be\n",
        "                    # removed later.\n",
        "                    X_mask[:, i] = valid_mask\n",
        "                    X[:, i][~valid_mask] = self.categories_[i][0]\n",
        "            X_int[:, i] = self._label_encoders_[i].transform(X[:, i])\n",
        "\n",
        "        if self.encoding == 'ordinal':\n",
        "            return X_int.astype(self.dtype, copy=False)\n",
        "\n",
        "        mask = X_mask.ravel()\n",
        "        n_values = [cats.shape[0] for cats in self.categories_]\n",
        "        n_values = np.array([0] + n_values)\n",
        "        indices = np.cumsum(n_values)\n",
        "\n",
        "        column_indices = (X_int + indices[:-1]).ravel()[mask]\n",
        "        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n",
        "                                n_features)[mask]\n",
        "        data = np.ones(n_samples * n_features)[mask]\n",
        "\n",
        "        out = sparse.csc_matrix((data, (row_indices, column_indices)),\n",
        "                                shape=(n_samples, indices[-1]),\n",
        "                                dtype=self.dtype).tocsr()\n",
        "        if self.encoding == 'onehot-dense':\n",
        "            return out.toarray()\n",
        "        else:\n",
        "            return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "60d1cff07a813108f6e0aea6bef099f2e676f3df",
        "_cell_guid": "aa68fb0d-4b6b-4169-83d0-d051ed423833",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "mJdb3VOyCNYs"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# A class to select numerical or categorical columns\n",
        "# since Scikit-Learn doesn't handle DataFrames yet\n",
        "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, attribute_names):\n",
        "        self.attribute_names = attribute_names\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return X[self.attribute_names]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3ce3c156e96931689a8be356cfc77e117a856380",
        "_cell_guid": "8cf62548-2215-448e-ae98-31c336693c6b",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "fHZ0vAdICNYs"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Columns to delete or fix: earliest_cr_line, last_pymnt_d, next_pymnt_d, last_credit_pull_d, verification_status_joint\n",
        "\n",
        "numeric = X_train.select_dtypes(exclude=[\"object\"])\n",
        "categorical = X_train.select_dtypes([\"object\"])\n",
        "\n",
        "numeric_pipeline = Pipeline([\n",
        "    ('selector', DataFrameSelector(numeric.columns.tolist())),\n",
        "    ('scaler', StandardScaler()),\n",
        "])\n",
        "\n",
        "categorical_pipeline = Pipeline([\n",
        "    ('selector', DataFrameSelector(categorical.columns.tolist())), # We will have to write the categorical columns manually and see if it works.\n",
        "    ('encoder', CategoricalEncoder(encoding=\"onehot-dense\")),\n",
        "])\n",
        "\n",
        "# Combine both Pipelines into one array\n",
        "combined_pipeline = FeatureUnion(transformer_list=[\n",
        "    ('numeric_pipeline', numeric_pipeline),\n",
        "    ('categorical_pipeline', categorical_pipeline)\n",
        "])\n",
        "\n",
        "X_train = combined_pipeline.fit_transform(X_train)\n",
        "X_test = combined_pipeline.fit_transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1eae7a82feca2f247d3268bccdaf5a6a8c20173c",
        "_cell_guid": "57d44d63-7e0a-42ca-a7d2-e244d96dc5cd",
        "id": "90AcVg6zCNYs"
      },
      "cell_type": "markdown",
      "source": [
        "### Next Phase of our Analysis is to Oversample Our data using SMOTE Technique\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "d0fa8501b28cfc8412beeb828fc8a1e97fe3ca91",
        "_cell_guid": "c96620cd-111b-40b6-a595-e8903d8a6444",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "TVxuAOqmCNYs"
      },
      "cell_type": "code",
      "source": [
        "# Oversampled Train Set (Goes after encoding and scaling!)\n",
        "# starting_time = time.time()\n",
        "# sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "# X_train_sm, y_train_sm = sm.fit_sample(X_train, y_train)\n",
        "# ending_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7795c6c9c473f29985d8aaa512398663078b7c77",
        "_cell_guid": "5882931f-97ad-4d09-b9c5-6e80ee7c986f",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "2UUp3LERCNYt"
      },
      "cell_type": "code",
      "source": [
        "# print(\"Resampling the data took: {:.2f} minutes!\".format(round((ending_time - starting_time)/60), 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fd800cbeb4294bffbfa49925f1803c0d773c1919",
        "_cell_guid": "3e0a2bca-6844-48d7-8256-d252e2cf59c7",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "aFTSouF8CNYt"
      },
      "cell_type": "code",
      "source": [
        "# Labels have been resampled\n",
        "# Counter(y_train_sm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8142236382029dcdb8442bb84f9391375429e299",
        "_cell_guid": "c17715bb-d021-4c0c-8a4a-9836440ad623",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "8f2Jdm0GCNYt"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "# log_reg_sm = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2c4e2c637c2fb1209cdf26e125df0c2dfea77ab3",
        "_cell_guid": "97cbbac7-8a46-452d-9d2d-02b9cc8618e0",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "kvEDopACCNYt"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "normal_ypred = log_reg.predict(X_test)\n",
        "print(accuracy_score(y_test, normal_ypred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6f34f021bade61dd06e9670eacdecd48111f0dcb",
        "_cell_guid": "541a6985-b75e-4dca-ad89-1dd9fa6b24af",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "Pi5Vm-x3CNYu"
      },
      "cell_type": "code",
      "source": [
        "# Reset graph in case of reusing\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "def fetch_batch(epoch, batch_index, batch_size, instances=X_train.shape[0]):\n",
        "    np.random.seed(epoch * n_batches + batch_index)\n",
        "    indices = np.random.randint(instances, size=batch_size)\n",
        "    X_batch = X_train[indices]\n",
        "    y_batch = y_train[indices]\n",
        "    return X_batch, y_batch\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "\n",
        "# Directory to access tensorboard\n",
        "# now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "# root_logdir = \"tf_logs\"\n",
        "# LOGDIR = \"{}/run-{}/\".format(root_logdir, now)\n",
        "\n",
        "# Neural Network with TensorFlow\n",
        "\n",
        "n_inputs = X_train.shape[1]\n",
        "hidden1_amount = 66\n",
        "hidden2_amount = 66\n",
        "n_outputs = 2\n",
        "\n",
        "# Placeholders\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
        "\n",
        "# Architectural Structure\n",
        "with tf.name_scope('dnn'):\n",
        "    hidden1 = tf.layers.dense(X, hidden1_amount, activation=tf.nn.relu, name=\"first_layer\")\n",
        "    hidden2 = tf.layers.dense(hidden1, hidden2_amount, activation=tf.nn.relu, name=\"second_layer\")\n",
        "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
        "\n",
        "# Loss Functions\n",
        "with tf.name_scope(\"loss\"):\n",
        "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
        "                                                                  logits=logits)\n",
        "    loss = tf.reduce_mean(cross_entropy, name=\"loss\")\n",
        "\n",
        "# optimizer\n",
        "learning_rate = 0.01\n",
        "\n",
        "with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "    best_op = optimizer.minimize(loss)\n",
        "\n",
        "# Evaluating\n",
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "06120beb541ce24895ab0f80c5addc7b5b836809",
        "_cell_guid": "879ad0e4-baf9-4f48-a5e6-c405f0ed0b15",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "rEIa4ICnCNYv"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 250\n",
        "n_batches = int(np.ceil(X_train.shape[0]/ batch_size))\n",
        "n_epochs = 10\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for batch_index in range(n_batches):\n",
        "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
        "            sess.run(best_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_test, y: y_test})\n",
        "        print(epoch+1, \"Loss:{:.5f}\\t Accuracy:{:.3f}%\".format(loss_val, acc_val * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "778d482965a573e604d634aeea24195b061c2a31",
        "id": "OADHmBRGCNYv"
      },
      "cell_type": "markdown",
      "source": [
        "### Architecture of the Neural Network:"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e0c5bc1e66d539fb999cbaabc57ae8723251b77a",
        "id": "K9I7kGFMCNYv"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output, Image, display, HTML\n",
        "\n",
        "def strip_consts(graph_def, max_const_size=32):\n",
        "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
        "    strip_def = tf.GraphDef()\n",
        "    for n0 in graph_def.node:\n",
        "        n = strip_def.node.add()\n",
        "        n.MergeFrom(n0)\n",
        "        if n.op == 'Const':\n",
        "            tensor = n.attr['value'].tensor\n",
        "            size = len(tensor.tensor_content)\n",
        "            if size > max_const_size:\n",
        "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
        "    return strip_def\n",
        "\n",
        "def show_graph(graph_def, max_const_size=32):\n",
        "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
        "    if hasattr(graph_def, 'as_graph_def'):\n",
        "        graph_def = graph_def.as_graph_def()\n",
        "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
        "    code = \"\"\"\n",
        "        <script>\n",
        "          function load() {{\n",
        "            document.getElementById(\"{id}\").pbtxt = {data};\n",
        "          }}\n",
        "        </script>\n",
        "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
        "        <div style=\"height:600px\">\n",
        "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
        "        </div>\n",
        "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
        "\n",
        "    iframe = \"\"\"\n",
        "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
        "    \"\"\".format(code.replace('\"', '&quot;'))\n",
        "    display(HTML(iframe))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2aabed9e6423f9d3c1f7306391538fa829f6392e",
        "id": "2nk1Ve4bCNYw",
        "outputId": "b7953f70-5801-4990-d8e7-e4cfbc085d12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "cell_type": "code",
      "source": [
        "show_graph(tf.get_default_graph().as_graph_def())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-779d621fa9ee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "afddcbd5f4363d393a7471f613d14ec22205f0fa",
        "_cell_guid": "3fe76f2a-6186-4434-b58e-7ff633f532f2",
        "id": "pO59z7jWCNYw"
      },
      "cell_type": "markdown",
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}